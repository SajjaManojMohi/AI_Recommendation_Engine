{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381eb2d4-dd59-44c7-8c4b-42c34f03889b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 22001\n",
      "Test size: 5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cool\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\cool\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\cool\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== FINAL COMPARISON ==========\n",
      "\n",
      "         Model      RMSE  Precision    Recall        F1  Precision@10  \\\n",
      "0   Popularity  1.142827   0.646688  0.056881  0.104565      0.004654   \n",
      "1     User-KNN  3.694987   0.000000  0.000000  0.000000      0.022751   \n",
      "2     Item-KNN  3.726156   0.000000  0.000000  0.000000      0.023681   \n",
      "3  Vanilla SVD  2.969583   0.000000  0.000000  0.000000      0.019855   \n",
      "4     Bias-SVD  1.180370   0.655943  0.203663  0.310819      0.005791   \n",
      "\n",
      "   Recall@10  \n",
      "0   0.013113  \n",
      "1   0.058275  \n",
      "2   0.061673  \n",
      "3   0.049238  \n",
      "4   0.016463  \n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# RESEARCH-GRADE RECOMMENDER SYSTEM COMPARISON\n",
    "# ==========================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 1. LOAD DATA\n",
    "# ==========================================================\n",
    "\n",
    "df1 = pd.read_csv(\"users_interactions.csv\")\n",
    "df2 = pd.read_csv(\"products_catalog.csv\")\n",
    "\n",
    "df1 = df1.drop(\"timestamp\", axis=1)\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df1,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "threshold = 4\n",
    "K = 10\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Test size:\", len(test_df))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 2. CREATE USER/ITEM MAPS\n",
    "# ==========================================================\n",
    "\n",
    "user_ids = train_df[\"user_id\"].unique()\n",
    "product_ids = train_df[\"product_id\"].unique()\n",
    "\n",
    "user_map = {u: i for i, u in enumerate(user_ids)}\n",
    "item_map = {p: i for i, p in enumerate(product_ids)}\n",
    "\n",
    "num_users = len(user_ids)\n",
    "num_items = len(product_ids)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 3. BUILD RATING MATRIX\n",
    "# ==========================================================\n",
    "\n",
    "rows = train_df[\"user_id\"].map(user_map)\n",
    "cols = train_df[\"product_id\"].map(item_map)\n",
    "ratings = train_df[\"rating\"]\n",
    "\n",
    "R = csr_matrix((ratings, (rows, cols)), shape=(num_users, num_items))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 4. EVALUATION FUNCTION\n",
    "# ==========================================================\n",
    "\n",
    "def evaluate(predicted_matrix, model_name):\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        u = row[\"user_id\"]\n",
    "        i = row[\"product_id\"]\n",
    "\n",
    "        if u in user_map and i in item_map:\n",
    "            u_idx = user_map[u]\n",
    "            i_idx = item_map[i]\n",
    "\n",
    "            y_true.append(row[\"rating\"])\n",
    "            y_pred.append(predicted_matrix[u_idx, i_idx])\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    y_true_bin = [1 if r >= threshold else 0 for r in y_true]\n",
    "    y_pred_bin = [1 if r >= threshold else 0 for r in y_pred]\n",
    "\n",
    "    precision = precision_score(y_true_bin, y_pred_bin)\n",
    "    recall = recall_score(y_true_bin, y_pred_bin)\n",
    "    f1 = f1_score(y_true_bin, y_pred_bin)\n",
    "\n",
    "    # Precision@K / Recall@K\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for user in test_df[\"user_id\"].unique():\n",
    "        if user not in user_map:\n",
    "            continue\n",
    "\n",
    "        u_idx = user_map[user]\n",
    "        user_preds = predicted_matrix[u_idx].copy()\n",
    "\n",
    "        rated_items = R[u_idx].indices\n",
    "        user_preds[rated_items] = -np.inf\n",
    "\n",
    "        top_k_idx = np.argsort(user_preds)[-K:][::-1]\n",
    "        top_k_items = set(product_ids[i] for i in top_k_idx)\n",
    "\n",
    "        user_test = test_df[\n",
    "            (test_df[\"user_id\"] == user) &\n",
    "            (test_df[\"rating\"] >= threshold)\n",
    "        ]\n",
    "\n",
    "        relevant_items = set(user_test[\"product_id\"])\n",
    "\n",
    "        if len(relevant_items) == 0:\n",
    "            continue\n",
    "\n",
    "        hits = len(top_k_items & relevant_items)\n",
    "\n",
    "        precisions.append(hits / K)\n",
    "        recalls.append(hits / len(relevant_items))\n",
    "\n",
    "    precision_k = np.mean(precisions)\n",
    "    recall_k = np.mean(recalls)\n",
    "\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "        \"Precision@10\": precision_k,\n",
    "        \"Recall@10\": recall_k\n",
    "    }\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 5. MODEL 1 — POPULARITY\n",
    "# ==========================================================\n",
    "\n",
    "item_mean = train_df.groupby(\"product_id\")[\"rating\"].mean()\n",
    "global_mean = train_df[\"rating\"].mean()\n",
    "\n",
    "pop_pred = np.full((num_users, num_items), global_mean)\n",
    "\n",
    "for item, mean in item_mean.items():\n",
    "    if item in item_map:\n",
    "        pop_pred[:, item_map[item]] = mean\n",
    "\n",
    "results.append(evaluate(pop_pred, \"Popularity\"))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 6. MODEL 2 — USER KNN\n",
    "# ==========================================================\n",
    "\n",
    "user_sim = cosine_similarity(R)\n",
    "user_sim[np.isnan(user_sim)] = 0\n",
    "\n",
    "user_knn_pred = user_sim @ R.toarray()\n",
    "norm = np.abs(user_sim).sum(axis=1, keepdims=True)\n",
    "user_knn_pred = user_knn_pred / np.where(norm == 0, 1, norm)\n",
    "\n",
    "results.append(evaluate(user_knn_pred, \"User-KNN\"))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 7. MODEL 3 — ITEM KNN\n",
    "# ==========================================================\n",
    "\n",
    "item_sim = cosine_similarity(R.T)\n",
    "item_sim[np.isnan(item_sim)] = 0\n",
    "\n",
    "item_knn_pred = R.toarray() @ item_sim\n",
    "norm = np.abs(item_sim).sum(axis=1)\n",
    "item_knn_pred = item_knn_pred / np.where(norm == 0, 1, norm)\n",
    "\n",
    "results.append(evaluate(item_knn_pred, \"Item-KNN\"))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 8. MODEL 4 — VANILLA SVD\n",
    "# ==========================================================\n",
    "\n",
    "U, sigma, Vt = svds(R, k=50)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "svd_pred = U @ sigma @ Vt\n",
    "svd_pred = np.clip(svd_pred, 1, 5)\n",
    "\n",
    "results.append(evaluate(svd_pred, \"Vanilla SVD\"))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 9. MODEL 5 — BIAS-SVD\n",
    "# ==========================================================\n",
    "\n",
    "global_mean = train_df[\"rating\"].mean()\n",
    "\n",
    "user_bias = np.array([\n",
    "    R[u].data.mean() - global_mean if len(R[u].data) > 0 else 0\n",
    "    for u in range(num_users)\n",
    "])\n",
    "\n",
    "item_bias = np.array([\n",
    "    R[:, i].data.mean() - global_mean if len(R[:, i].data) > 0 else 0\n",
    "    for i in range(num_items)\n",
    "])\n",
    "\n",
    "R_centered = R.copy().tolil()\n",
    "\n",
    "for u in range(num_users):\n",
    "    for idx in range(len(R_centered.data[u])):\n",
    "        i = R_centered.rows[u][idx]\n",
    "        R_centered.data[u][idx] -= (global_mean + user_bias[u] + item_bias[i])\n",
    "\n",
    "R_centered = R_centered.tocsr()\n",
    "\n",
    "U, sigma, Vt = svds(R_centered, k=50)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "bias_svd_pred = U @ sigma @ Vt\n",
    "\n",
    "for u in range(num_users):\n",
    "    bias_svd_pred[u, :] += global_mean + user_bias[u] + item_bias\n",
    "\n",
    "bias_svd_pred = np.clip(bias_svd_pred, 1, 5)\n",
    "\n",
    "results.append(evaluate(bias_svd_pred, \"Bias-SVD\"))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 10. FINAL RESULTS TABLE\n",
    "# ==========================================================\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n========== FINAL COMPARISON ==========\\n\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
